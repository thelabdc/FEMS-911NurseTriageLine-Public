{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from femsntl.datafiles import INTERMEDIATE_DIR, PRIVATE_DATA_DIR\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option(\"display.max_columns\", None)  # or 1000\n",
    "pd.set_option(\"display.max_rows\", None)  # or 1000\n",
    "pd.set_option(\"display.max_colwidth\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PULL_SQL_EVEN_IF_EXISTS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data from previous script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntl_analytic = pd.read_pickle(INTERMEDIATE_DIR / \"ntl_withsafetypad.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique participants at start:\", ntl_analytic.num_1.nunique())\n",
    "ntl_tx = ntl_analytic.loc[ntl_analytic.dispo_broad == \"NTL treatment\"].copy()\n",
    "ntl_control = ntl_analytic.loc[ntl_analytic.dispo_broad == \"NTL control\"].copy()\n",
    "print(\"Number of unique tx group\", ntl_tx.num_1.nunique())\n",
    "print(\"Number of unique control group\", ntl_tx.num_1.nunique())\n",
    "\n",
    "## get number in other categories and why\n",
    "non_txcont = (\n",
    "    ntl_analytic.loc[~ntl_analytic.dispo_broad.isin([\"NTL control\", \"NTL treatment\"])]\n",
    "    .copy()\n",
    "    .drop_duplicates(subset=\"num_1\")\n",
    ")\n",
    "pd.crosstab(non_txcont.dispo_broad, non_txcont.event_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load AMR data without medicaid ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_df = pd.read_excel(PRIVATE_DATA_DIR / \"amr_df.xlsx\", sheet_name=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load AMR data with Medicaid ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_df_withmedicaid = pd.read_excel(\n",
    "    PRIVATE_DATA_DIR / \"dc_fems_medicaidids.xlsx\", sheet_name=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_df_withmedicaid = pd.read_excel(\n",
    "    PRIVATE_DATA_DIR / \"dc_fems_medicaidids.xlsx\", sheet_name=0, skiprows=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create flags for which participants are in which data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Medicaid ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_respondents_withmedids = amr_df_withmedicaid.loc[\n",
    "    amr_df_withmedicaid[\"Personal ID Number\"] != \"-\"\n",
    "].copy()\n",
    "\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(len(amr_respondents_withmedids[\"Personal ID Number\"].unique()))\n",
    "    + \" unique medicaid ids, corresponding to \"\n",
    "    + str(len(amr_respondents_withmedids.FEMSID.unique()))\n",
    "    + \" calls\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fems_ids_forresp_withmedicaid = amr_respondents_withmedids.FEMSID.unique()\n",
    "\n",
    "found_in_analytic = set(fems_ids_forresp_withmedicaid).intersection(\n",
    "    set(ntl_analytic.num_1)\n",
    ")\n",
    "print(\n",
    "    \"But \"\n",
    "    + str(len(found_in_analytic))\n",
    "    + \" of their FEMS IDs are found in analytic sample of NTL callers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 since Ids are off, try merging with amr data by name and dob exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_respondents_withmedids[\n",
    "    \"fname_cap\"\n",
    "] = amr_respondents_withmedids.PatientFName.astype(str).str.upper()\n",
    "amr_respondents_withmedids[\n",
    "    \"lname_cap\"\n",
    "] = amr_respondents_withmedids.PatientLName.astype(str).str.upper()\n",
    "amr_respondents_withmedids[\"name_dob\"] = (\n",
    "    amr_respondents_withmedids.fname_cap\n",
    "    + \"_\"\n",
    "    + amr_respondents_withmedids.lname_cap\n",
    "    + \"_\"\n",
    "    + amr_respondents_withmedids.DOB.astype(str)\n",
    ")\n",
    "\n",
    "## create similar column in amr data\n",
    "amr_df[\"fname_cap\"] = amr_df.PatientFName.astype(str).str.upper()\n",
    "amr_df[\"lname_cap\"] = amr_df.PatientLName.astype(str).str.upper()\n",
    "amr_df[\"dob_strip0\"] = [\n",
    "    str(one_dob).replace(\" 00:00:00\", \"\") for one_dob in amr_df.DateofBirth\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_df[\"name_dob\"] = (\n",
    "    amr_df.fname_cap + \"_\" + amr_df.lname_cap + \"_\" + amr_df.dob_strip0\n",
    ")  # type c\n",
    "\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(\n",
    "        len(set(amr_df.name_dob).intersection(set(amr_respondents_withmedids.name_dob)))\n",
    "    )\n",
    "    + \" exact matches on name and dob to add medicaid ids out of \"\n",
    "    + str(len(amr_respondents_withmedids[\"Personal ID Number\"].unique()))\n",
    "    + \" Medicaid IDs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## left join relevant columns so that those participants\n",
    "## have medicaid ids\n",
    "amr_df_withmedid = pd.merge(\n",
    "    amr_df,\n",
    "    amr_respondents_withmedids[[\"Personal ID Number\", \"name_dob\"]].drop_duplicates(\n",
    "        keep=\"first\"\n",
    "    ),\n",
    "    on=\"name_dob\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "## check pre and post-merge n\n",
    "print(\"There are \" + str(len(amr_df.FEMSID.unique())) + \" unique calls pre-merge\")\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(len(amr_df_withmedid.FEMSID.unique()))\n",
    "    + \" unique calls post-merge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 create categories of identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create different status codes\n",
    "all_ids = ntl_analytic.num_1.unique().tolist()\n",
    "ids_insafetyPAD = (\n",
    "    ntl_analytic.loc[ntl_analytic.incident_number.notnull(), \"num_1\"].unique().tolist()\n",
    ")\n",
    "ids_inAMR_nomedicaidid = (\n",
    "    amr_df_withmedid.loc[amr_df_withmedid[\"Personal ID Number\"].isnull(), \"FEMSID\"]\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "ids_inAMR_medicaidid = (\n",
    "    amr_df_withmedid.loc[amr_df_withmedid[\"Personal ID Number\"].notnull(), \"FEMSID\"]\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "ids_inAMR = ids_inAMR_medicaidid + ids_inAMR_nomedicaidid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create different categories\n",
    "ids_AMRsafetyPAD = np.unique(list(set(ids_insafetyPAD).intersection(set(ids_inAMR))))\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(len(ids_AMRsafetyPAD))\n",
    "    + \" ids in both AMR data and safety pad data\"\n",
    ")\n",
    "ids_safetyPAD_notAMR = np.unique(list(set(ids_insafetyPAD).difference(set(ids_inAMR))))\n",
    "print(\"There are \" + str(len(ids_safetyPAD_notAMR)) + \" ids in safetyPAD but not AMR\")\n",
    "ids_AMR_notsafetyPAD = np.unique(list(set(ids_inAMR).difference(set(ids_insafetyPAD))))\n",
    "print(\"There are \" + str(len(ids_AMR_notsafetyPAD)) + \" ids in AMR but not safetypad\")\n",
    "ids_AMR_safetyPAD = ids_insafetyPAD + ids_inAMR\n",
    "ids_neitherAMR_norsafetyPAD = np.unique(\n",
    "    list(set(all_ids).difference(set(ids_AMR_safetyPAD)))\n",
    ")\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(len(ids_neitherAMR_norsafetyPAD))\n",
    "    + \" ids in neither AMR nor safetypad\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the ntl analytic as base, and code id status\n",
    "ntl_analytic[\"data_status\"] = np.where(\n",
    "    ntl_analytic.num_1.isin(ids_AMRsafetyPAD),\n",
    "    \"In both Safety PAD and AMR data\",\n",
    "    np.where(\n",
    "        ntl_analytic.num_1.isin(ids_safetyPAD_notAMR),\n",
    "        \"In Safety PAD but not AMR\",\n",
    "        np.where(\n",
    "            ntl_analytic.num_1.isin(ids_AMR_notsafetyPAD),\n",
    "            \"In AMR but not SafetyPAD\",\n",
    "            np.where(\n",
    "                ntl_analytic.num_1.isin(\n",
    "                    ids_neitherAMR_norsafetyPAD\n",
    "                ),  # even though this should be remainder, coding explicitly\n",
    "                \"In neither AMR nor safetyPAD\",\n",
    "                \"Other\",\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "ntl_analytic[\"medicaid_id_status\"] = np.where(\n",
    "    ntl_analytic.num_1.isin(ids_inAMR_medicaidid), \"Has Medicaid id\", \"No Medicaid id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep each ids first appearance\n",
    "## for purposes of summarizing ID status\n",
    "ntl_analytic_firstappearance = ntl_analytic.sort_values(by=\"date\").drop_duplicates(\n",
    "    subset=\"num_1\", keep=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntl_analytic_firstappearance.dispo_broad.value_counts()  # check that equal to 3032; 3023 before summarizing\n",
    "pd.crosstab(\n",
    "    ntl_analytic_firstappearance.dispo_broad, ntl_analytic_firstappearance.data_status\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    ntl_analytic_firstappearance.dispo_broad,\n",
    "    ntl_analytic_firstappearance.medicaid_id_status,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    ntl_analytic_firstappearance.event_status, ntl_analytic_firstappearance.data_status\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Merge the data-- creating different columns for identifiers from different sources\n",
    "\n",
    "Left join so that all respondents are retained. Those with records in both will have identifiers from both. Those with data\n",
    "from neither will be NA in both; etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_newcolnames = [\n",
    "    \"amr_\" + col if col != \"FEMSID\" else col for col in amr_df_withmedid.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_df_withmedid.columns = amr_newcolnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## left join onto main data\n",
    "ntl_analytic_withamr = pd.merge(\n",
    "    ntl_analytic, amr_df_withmedid, left_on=\"num_1\", right_on=\"FEMSID\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_phone_to_int(phone_number: Union[int, str]) -> int:\n",
    "    try:\n",
    "        return str(int(phone_number))\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Assume string and remove - characters\n",
    "            return str(int(re.sub(r\"[^0-9]\", \"\", phone_number)))\n",
    "        except ValueError:\n",
    "            return phone_number\n",
    "\n",
    "\n",
    "ntl_analytic_withamr[\n",
    "    \"amr_ApplicantsPhone\"\n",
    "] = ntl_analytic_withamr.amr_ApplicantsPhone.map(\n",
    "    convert_phone_to_int, na_action=\"ignore\"\n",
    ")\n",
    "ntl_analytic_withamr[\"amr_PatientLName\"] = ntl_analytic_withamr.amr_PatientLName.map(\n",
    "    str, na_action=\"ignore\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## also write medicaid id data in case useful after names clean up\n",
    "amr_df_withmedid[amr_df_withmedid[\"amr_Personal ID Number\"].notnull()].to_csv(\n",
    "    INTERMEDIATE_DIR / \"medicaid_ids.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write data to use in lookup script (that script will do cleaning)\n",
    "ntl_analytic_withamr.to_pickle(INTERMEDIATE_DIR / \"ntl_withsafetypad_withamr.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
