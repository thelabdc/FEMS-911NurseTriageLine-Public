{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from femsntl.datafiles import INTERMEDIATE_DIR, PUBLIC_DATA_DIR\n",
    "from femsntl.df_verbs import case_when\n",
    "from femsntl.utils import get_mostrec\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.options.display.float_format = \"{:.4f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to migrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three units of analysis:\n",
    "\n",
    "- `code-level`: the raw form of the claims data. Each unique claim (`ClaimTCNText`) is repeated with different information about that claim included --- e.g., one claim might be tied to multiple codes indicating diff procedures performed or specialists seen\n",
    "- `claim-level`: aggregates up from codes to unique claims\n",
    "- `beneficiary (bene)-level`: aggregates up from claims to unique medicaid beneficiaries (`MedicaidSystemID`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_edvisit(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to code whether a visit is an emergency dept (ED) visit\n",
    "\n",
    "    Args:\n",
    "        df: code-level df with fields relevant for ED visits\n",
    "\n",
    "    Returns:\n",
    "       output_df: dataset grouped by unique claims coding whether any visits associated with\n",
    "       that claim are an ed visit and/or an inpatient admit, as well as two fields we\n",
    "       need for later transformations (MedicaidSystemID and primarydiagnosiscode, latter is used\n",
    "       to code ED necessity of visit)\n",
    "\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # code binary indicator for any ed visit associated with claim\n",
    "    df[\"is_ed_visit\"] = df.RevenueCode.isin(ED_VISIT_CODES)\n",
    "    df[\"is_inpatient_admit\"] = df.RevenueCode.isin(ROOM_BOARD_CODES)\n",
    "\n",
    "    # Claims can have multiple revenue codes, and the passed df has one\n",
    "    # revenue code per line, grouped together by ClaimTCNText. So we\n",
    "    # aggregate to the claim level and code as an ED visit if:\n",
    "    #   1. There is at least one ed_visit code, and\n",
    "    #   2. There are NO inpatient revenue codes\n",
    "    #\n",
    "    # This relies on there being one primary diagnosis code per ClaimTCNText\n",
    "    # which we assert here:\n",
    "    assert (df.groupby(\"ClaimTCNText\")[\"PrimaryDiagnosisCode\"].nunique() == 1).all()\n",
    "\n",
    "    output_df = (\n",
    "        df.groupby(\"ClaimTCNText\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"is_ed_visit\": \"max\",\n",
    "                \"is_inpatient_admit\": \"max\",\n",
    "                \"MedicaidSystemID\": \"first\",\n",
    "                \"PrimaryDiagnosisCode\": \"first\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    output_df[\"is_ed_visit_not_inpatient\"] = (\n",
    "        output_df[\"is_ed_visit\"] & ~output_df[\"is_inpatient_admit\"]\n",
    "    )\n",
    "    output_df[\"is_ed_visit_with_inpatient\"] = (\n",
    "        output_df[\"is_ed_visit\"] & output_df[\"is_inpatient_admit\"]\n",
    "    )\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def mergeclaims_beneficiaries(\n",
    "    claims_df: pd.DataFrame, benef_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to merge claims onto beneficiaries\n",
    "\n",
    "    Args:\n",
    "        claims_df: code or claim-level df w/ things repeated across the same beneficiary\n",
    "        benef_df: beneficiary-level data frame\n",
    "\n",
    "    Returns:\n",
    "       merged_df: beneficiary-level dataset where each beneficiary is repeated across claims\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## subset benef df to merge-relevant fields\n",
    "    benef_df = benef_df[[\"num_1\", \"dispo_broad\", \"event_status\", \"MedicaidSystemID\"]]\n",
    "\n",
    "    ## left join claims onto beneficiaries\n",
    "    ## we want to retain all beneficaries even if they have no claims (left)\n",
    "    ## but we drop claims that are not linked to a beneficiary (since claims pull\n",
    "    ## based on more inclusive match to beneficiaries than we're using)\n",
    "    merged_df = pd.merge(benef_df, claims_df, on=\"MedicaidSystemID\", how=\"left\")\n",
    "\n",
    "    ## Make sure nothing lost in the merge\n",
    "    assert (\n",
    "        benef_df[\"MedicaidSystemID\"].nunique()\n",
    "        == merged_df[\"MedicaidSystemID\"].nunique()\n",
    "    )\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def construct_nonED_care(\n",
    "    df: pd.DataFrame, claim_types_to_remove: List[str]\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Function to code whether a visit is a general non-ED visit\n",
    "\n",
    "    Args:\n",
    "        df: code-level df with revenue and procedure codes relevant for coding\n",
    "\n",
    "    Returns:\n",
    "       output_df: claim-level df indicating any qualify within the claim\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    ## code binary indicator for any ed visit associated with claim\n",
    "    df[\"is_not_general_care\"] = (\n",
    "        df.RevenueCode.isin(ED_VISIT_CODES)\n",
    "        | df.ProcedureCode.isin(ED_PHYSICIAN_CODES)\n",
    "        | df.ClaimTypeDescription.isin(claim_types_to_remove)\n",
    "    )\n",
    "\n",
    "    df[\"is_general_care\"] = ~df[\"is_not_general_care\"]\n",
    "\n",
    "    # Our input df has one row per _code_, we want one row per _claim_\n",
    "    return (\n",
    "        df.groupby(\"ClaimTCNText\")\n",
    "        .agg({\"is_general_care\": \"max\", \"MedicaidSystemID\": \"first\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "DEFAULT_VARS_TO_INCLUDE = [\"MedicaidSystemID\", \"dispo_broad\", \"event_status\", \"num_1\"]\n",
    "\n",
    "\n",
    "def code_noclaims(\n",
    "    df: pd.DataFrame,\n",
    "    outcome_varnames: List[str],\n",
    "    code_to: bool = False,\n",
    "    vars_to_include: Optional[List[str]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to code outcomes for ntl-ers matched to the beneficiary file but with no claims in\n",
    "    a particular window\n",
    "\n",
    "    Args:\n",
    "        df: The data frame to code that contains people matched to beneficiaries file but w/ no claims in window\n",
    "        outcome_varnames: list of strings representing names of numeric-type vars to add\n",
    "        code_to: numeric value to impute\n",
    "        vars_to_include: vars from base data to retain\n",
    "\n",
    "    Returns:\n",
    "        df_pluscols: Data frame w/ outcomes coded for bene. with no claims\n",
    "        (diff than imputation bc we affirmatively observe 0)\n",
    "\n",
    "    \"\"\"\n",
    "    vars_to_include = vars_to_include or DEFAULT_VARS_TO_INCLUDE\n",
    "\n",
    "    df = df[vars_to_include].copy()\n",
    "    df_pluscols = df.reindex(\n",
    "        columns=[*df.columns.tolist(), *outcome_varnames], fill_value=code_to\n",
    "    )\n",
    "\n",
    "    return df_pluscols\n",
    "\n",
    "\n",
    "def summarize_bygroup(df: pd.DataFrame, col: str, col_type: str = \"binary\"):\n",
    "    \"\"\"\n",
    "    This function prints some basic summary statistics of the passed df,\n",
    "    which must have columns:\n",
    "        * \"dispo_broad\"\n",
    "        * `col`\n",
    "\n",
    "    Args:\n",
    "        df: The data frame to summarize\n",
    "        col: The column to cross tab against \"dispo_broad\"\n",
    "        col_type: One of:\n",
    "            * \"binary\": Prints a basic cross tab and one normalized by rows\n",
    "            * \"continuous\": Prints the mean of `col` for each \"dispo_broad\"\n",
    "    \"\"\"\n",
    "\n",
    "    if col_type == \"binary\":\n",
    "        print(pd.crosstab(df.dispo_broad, df[col]))\n",
    "        print(pd.crosstab(df.dispo_broad, df[col], normalize=\"index\"))\n",
    "\n",
    "    elif col_type == \"continuous\":\n",
    "        print(df.groupby(\"dispo_broad\")[col].mean())\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"col_type must be one of ['binary', 'continuous'] not {col_type}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def merge_dx_classification(\n",
    "    data: pd.DataFrame, icd_classify_data: pd.DataFrame, time_horizon: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to clean primary dx codes attached to a claim and merge with icd codes\n",
    "\n",
    "    Args:\n",
    "       data: code or claim-level data with primarydx code\n",
    "       icd_classify_data:\n",
    "\n",
    "    Returns:\n",
    "        df_pluscols: Data frame w/ outcomes coded for bene. with no claims\n",
    "        (diff than imputation bc we affirmatively observe 0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## clean dx code\n",
    "    data[\"primarydx_tomerge\"] = data.PrimaryDiagnosisCode.str.replace(\"\\\\.\", \"\")\n",
    "\n",
    "    ## print match rate\n",
    "    print(\n",
    "        \"Out of \"\n",
    "        + str(len(data.primarydx_tomerge.unique()))\n",
    "        + \" unique dx codes in callers claims in \"\n",
    "        + time_horizon\n",
    "        + \" we matched \"\n",
    "        + str(len(set(data.primarydx_tomerge).intersection(icd_classify_data.icd10cm)))\n",
    "        + \" with the NYU classifications\"\n",
    "    )\n",
    "\n",
    "    ## merge onto claims using icd code\n",
    "    ## only merge for people with some claims\n",
    "    ## since we'll later code outcomes for\n",
    "    ## those with no claims\n",
    "    claims_wEDclass = pd.merge(\n",
    "        data,\n",
    "        icd_classify_data,\n",
    "        left_on=\"primarydx_tomerge\",\n",
    "        right_on=\"icd10cm\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    return claims_wEDclass\n",
    "\n",
    "\n",
    "def classify_visit_approp(\n",
    "    data: pd.DataFrame, edcol_touse: str = \"is_ed_visit_not_inpatient\"\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        data: The data frame to code\n",
    "        edcol_touse: list containing str w/ name of ed visit column (default excludes inpt admissions)\n",
    "\n",
    "    Returns:\n",
    "        df: df with different flags for unnec. ED visit\n",
    "    \"\"\"\n",
    "\n",
    "    data[\"edvisit_nonemergent\"] = case_when(\n",
    "        (data[edcol_touse]) & (data.Non_Emergent > 0),\n",
    "        \"ED visit; non-emergent\",\n",
    "        (data[edcol_touse]) & (data.Non_Emergent == 0),\n",
    "        \"ED visit; emergent\",\n",
    "        data[edcol_touse],\n",
    "        \"ED visit; unknown status\",\n",
    "        \"Not ED visit\",\n",
    "    )\n",
    "\n",
    "    data[\"edvisit_pctreatable\"] = case_when(\n",
    "        (data[edcol_touse]) & (data.Emergent__PC_Treatable > 0),\n",
    "        \"ED visit; PC treatable\",\n",
    "        (data[edcol_touse]) & (data.Emergent__PC_Treatable == 0),\n",
    "        \"ED visit; not PC treatable\",\n",
    "        data[edcol_touse],\n",
    "        \"ED visit; unknown status\",\n",
    "        \"Not ED visit\",\n",
    "    )\n",
    "\n",
    "    ## unnecessary is if it's non-emergent OR pc treatable\n",
    "    data[\"unnecessary_ED\"] = case_when(\n",
    "        (data.edvisit_nonemergent == \"ED visit; non-emergent\")\n",
    "        | (data.edvisit_pctreatable == \"ED visit; PC treatable\"),\n",
    "        \"Unnecessary ED visit (non-emergent or PC treatable)\",\n",
    "        (data.edvisit_nonemergent == \"ED visit; emergent\")\n",
    "        | (data.edvisit_pctreatable == \"ED visit; not PC treatable\"),\n",
    "        \"Necessary ED visit (emergent; not PC treatable)\",\n",
    "        (data.edvisit_nonemergent == \"ED visit; unknown status\")\n",
    "        | (data.edvisit_pctreatable == \"ED visit; unknown status\"),\n",
    "        \"Unclassified ED visit\",\n",
    "        \"Not ED visit\",\n",
    "    )\n",
    "\n",
    "    ## in addition to factor, create series of boolean flags to help with aggregation later\n",
    "    data[\"is_unnecessary_ED\"] = np.where(\n",
    "        data.unnecessary_ED == \"Unnecessary ED visit (non-emergent or PC treatable)\",\n",
    "        True,\n",
    "        False,\n",
    "    )\n",
    "    data[\"is_necessary_ED\"] = np.where(\n",
    "        data.unnecessary_ED == \"Necessary ED visit (emergent; not PC treatable)\",\n",
    "        True,\n",
    "        False,\n",
    "    )\n",
    "    data[\"is_unclassified_ED\"] = np.where(\n",
    "        data.unnecessary_ED == \"Unclassified ED visit\", True, False\n",
    "    )\n",
    "    data[\"is_not_ED\"] = np.where(data.unnecessary_ED == \"Not ED visit\", True, False)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def construct_binary_measures(data, outcome_vars):\n",
    "    \"\"\"\n",
    "    Function to construct binary measures from count or continuous data\n",
    "\n",
    "    Args:\n",
    "        data: The data frame to code\n",
    "        outcome_vars: outcome vars to binarize\n",
    "\n",
    "    Returns:\n",
    "        df: df with cols added for _1ormore (T/F) counts of that outcome\n",
    "    \"\"\"\n",
    "    for var in outcome_vars:\n",
    "        new_var = var + \"_1ormore\"\n",
    "        data[new_var] = np.where(data[var] >= 1, True, False)\n",
    "    return data\n",
    "\n",
    "\n",
    "def impute_nonmatch(\n",
    "    df: pd.DataFrame,\n",
    "    inclusion_method: str,\n",
    "    outcome_varnames: List[str],\n",
    "    code_to_fornumeric: int = np.nan,  # will change after bounding\n",
    "    vars_to_include: Optional[List[str]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        df: The data frame to code\n",
    "        inclusion_method: One of the following that tells which non-matches to Med beneficiaries to impute\n",
    "        outcomes for\n",
    "            * \"all\": include all non-matches, even if they had both name and dob, so a chance to be matched\n",
    "            * \"analytic_liberal\": include non-matches if they were missing both name and dob or had a call response (event_status)\n",
    "                                that was associated with lower match rates\n",
    "            * \"analytic_conservative\": only include non-matches if they were missing both name and dob\n",
    "        outcome_varnames: list of outcomes to code\n",
    "        vars_to_include: list of\n",
    "\n",
    "    Returns:\n",
    "        df: Data frame with outcomes imputed using bounding method/inclusion criteria\n",
    "    \"\"\"\n",
    "    vars_to_include = DEFAULT_VARS_TO_INCLUDE\n",
    "\n",
    "    if inclusion_method == \"all\":\n",
    "        pass\n",
    "    elif inclusion_method == \"analytic_liberal\":\n",
    "        df = df[\n",
    "            (df.is_miss_nameordob)\n",
    "            | df.event_status.isin(\n",
    "                [\n",
    "                    \"NTL Handled - Clinical Referral\",\n",
    "                    \"Field Requested NTL - NTL Clinical Referral\",\n",
    "                    \"NTL Handled - RSC\",\n",
    "                    \"NTL - Other\",\n",
    "                    \"Field Requested NTL - NTL Other\",\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    elif inclusion_method == \"analytic_conservative\":\n",
    "        df = df[df.is_miss_nameordob]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"inclusion_method must be one of ['all', 'analytic_liberal', 'analytic_conservative'] not {inclusion_method}\"\n",
    "        )\n",
    "\n",
    "    df = df[vars_to_include].copy()\n",
    "\n",
    "    ## first, add columns generally\n",
    "    df_add = df.reindex(\n",
    "        columns=[*df.columns.tolist(), *outcome_varnames], fill_value=code_to_fornumeric\n",
    "    )\n",
    "\n",
    "    ## then, add bounded versions\n",
    "    df_wbounds = bound_binary(df_add, outcome_varnames)\n",
    "\n",
    "    return df_wbounds\n",
    "\n",
    "\n",
    "def bound_binary(\n",
    "    data: pd.DataFrame, cols_tobound: List[\"str\"], optimistic_tx: bool = False\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Function to boundary binary outcomes for respondents who:\n",
    "    (1) did not match to Medicaid file but\n",
    "    (2) were flagged using the impute_nonmatch function as ones who had little chance of matching due to\n",
    "    missing identifiers\n",
    "\n",
    "    Args:\n",
    "        data: The data frame to code\n",
    "        cols_tobound: list of columns to create bounds for\n",
    "        optimistic_tx: value of optimistic bound for tx group members (others are variants of that)\n",
    "\n",
    "    Returns:\n",
    "        data: Data frame with bounded versions of columns\n",
    "\n",
    "    Assumes that all cols in cols_tobound are imputed in the same direction (for us, makes less sense for\n",
    "    the outcome of necessary ED visits but that's an unregistered outcome)\n",
    "\n",
    "    If need to impute in diff directions, run with separate lists of cols_tobound\n",
    "    \"\"\"\n",
    "\n",
    "    for col in cols_tobound:\n",
    "        data[col + \"_optimistic\"] = np.where(\n",
    "            data.dispo_broad == \"NTL treatment\",\n",
    "            optimistic_tx,  # in default, optimistic is that tx had none (false), control had some (true)\n",
    "            not optimistic_tx,\n",
    "        )  # relevant for \"bad\" outcomes like ed visits\n",
    "        data[col + \"_pessimistic\"] = np.where(\n",
    "            data.dispo_broad == \"NTL treatment\", not optimistic_tx, optimistic_tx\n",
    "        )\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_bounds_suffix(\n",
    "    vars_torename: List[str], df: pd.DataFrame, participant_group: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For medicaid beneficiaries for whom we do not need to do bounding, we\n",
    "    create copies of the variables with the relevant suffixes (content is unchanged but\n",
    "    just allows rowbinding)\n",
    "\n",
    "    Args:\n",
    "        vars_torename: list of vars we need to create suffixes for\n",
    "        df: main df\n",
    "        participant_group: so that we can later separate different types of groups of participants\n",
    "        (e.g., beneficiaries; nonbene)\n",
    "\n",
    "    Returns:\n",
    "        df_toret: dataframe with new suffixed-variables added and orig vars dropped\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for var in vars_torename:\n",
    "        df[var + \"_optimistic\"] = df[[var]]\n",
    "        df[var + \"_pessimistic\"] = df[[var]]\n",
    "\n",
    "    df_toret = df.drop(columns=vars_torename, inplace=False)\n",
    "    df_toret[\"participant_group\"] = participant_group\n",
    "    return df_toret\n",
    "\n",
    "\n",
    "def code_PCP_visits(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For medicaid beneficiaries who have some claims, code whether the claim is\n",
    "    associated with the pcp visit\n",
    "\n",
    "    Args:\n",
    "        df: dataframe at the claim level\n",
    "    Returns:\n",
    "        df: claim-level df with additional pcp-relevant columns\n",
    "    \"\"\"\n",
    "\n",
    "    ## is pcp\n",
    "    df[\"is_PCP_nofqhc\"] = (\n",
    "        (df.DetailRenderingSpecialtyCode.isin(specialty_codes))\n",
    "        | (df.BillingProviderTypeCode.isin(type_code))\n",
    "    ) & (df.ProcedureCode.isin(procedure_codes))\n",
    "\n",
    "    ## is fqhc\n",
    "    df[\"is_FQHC\"] = (df.BillingProviderTypeCode.isin(type_code)) & (\n",
    "        df.DetailRenderingSpecialtyCode.isin(fqhc_specialty_code)\n",
    "    )\n",
    "\n",
    "    ## is pcp visit\n",
    "    df[\"is_PCP_visit\"] = (df.is_PCP_nofqhc) | (df.is_FQHC)\n",
    "    return df\n",
    "\n",
    "\n",
    "def construct_ptlevel_PCP(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Two aggregations: (1) first, aggregate up to claim level (claimtcntext) so that one or more\n",
    "    subclaims counts as a PCP claim, (2) then, aggregate up to patient level to construct\n",
    "    boolean indicator for one or more pcp visits\n",
    "\n",
    "    Args:\n",
    "        df: dataframe at the claim level\n",
    "    Returns:\n",
    "        df: pt-level df with pcp binary indicator\n",
    "    \"\"\"\n",
    "\n",
    "    ## first aggregate to claim level and code whether a claim had any PCP visits\n",
    "    ## attached (don't want to count multiple PCP codes tied to\n",
    "    ## same claim as multiple PCP visits)\n",
    "    pcp_claimlevel = (\n",
    "        df.groupby(\"ClaimTCNText\")\n",
    "        .agg({\"is_PCP_visit\": \"sum\", \"MedicaidSystemID\": \"first\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    pcp_claimlevel[\"is_PCP_visit_claim\"] = np.where(\n",
    "        pcp_claimlevel.is_PCP_visit >= 1, True, False\n",
    "    )\n",
    "    pcp_ptlevel = (\n",
    "        pcp_claimlevel.groupby(\"MedicaidSystemID\")\n",
    "        .agg({\"is_PCP_visit_claim\": np.sum})\n",
    "        .reset_index()\n",
    "    )\n",
    "    pcp_ptlevel.columns = [\"MedicaidSystemID\", \"total_PCP\"]\n",
    "    pcp_ptlevel[\"is_PCP_oneormore\"] = np.where(pcp_ptlevel.total_PCP >= 1, True, False)\n",
    "    return pcp_ptlevel\n",
    "\n",
    "\n",
    "def summarize_expenditures(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Constructs total expenditures at the claim level through following steps:\n",
    "    (1) Filter out managed clair\n",
    "    (2) Sum expenditures for claims processed at header level (dropping duplicates on ClaimTCNText, which can result for added\n",
    "    details like different providers being tied to same claim/expenditure)\n",
    "    (3) Sum expenditures for claims processed at the detail level\n",
    "    (4) For both, then aggregate by beneficiary\n",
    "    (5) Merge a beneficiary's reimbursements across both levels\n",
    "\n",
    "    Args:\n",
    "        df: claim-level input data\n",
    "    Returns:\n",
    "        Patient-level data with total expenditures\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## filter out managed care\n",
    "    data_noMC = df[df.ClaimTypeDescription != \"Capitation (MC)\"].copy()\n",
    "\n",
    "    ## sum of claims processed at header level\n",
    "    vars_tosubset = [\n",
    "        \"MedicaidSystemID\",\n",
    "        \"ClaimProcessLevel\",\n",
    "        \"ClaimTCNText\",\n",
    "        \"HeaderTotalReimbursement\",\n",
    "    ]\n",
    "    header_reimburse_rows = (\n",
    "        data_noMC.loc[data_noMC.ClaimProcessLevel == \"Header\", vars_tosubset]\n",
    "        .copy()\n",
    "        .drop_duplicates(subset=\"ClaimTCNText\")\n",
    "    )\n",
    "    header_sum_by_benefic = (\n",
    "        header_reimburse_rows.groupby(\"MedicaidSystemID\")\n",
    "        .agg({\"HeaderTotalReimbursement\": np.sum})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    ## sum of claims processed at detail level\n",
    "    vars_tosubset = [\n",
    "        \"MedicaidSystemID\",\n",
    "        \"ClaimProcessLevel\",\n",
    "        \"ClaimTCNText\",\n",
    "        \"DetailReimbursementAmount\",\n",
    "    ]\n",
    "    detail_reimburse_rows = (\n",
    "        data_noMC.loc[data_noMC.ClaimProcessLevel == \"Detail\", vars_tosubset]\n",
    "        .copy()\n",
    "        .drop_duplicates(subset=\"ClaimTCNText\")\n",
    "    )\n",
    "\n",
    "    detail_sum_by_benefic = (\n",
    "        detail_reimburse_rows.groupby(\"MedicaidSystemID\")\n",
    "        .agg({\"DetailReimbursementAmount\": np.sum})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    ## left join each onto original claims\n",
    "    claims_wheader = pd.merge(\n",
    "        data_noMC[[\"MedicaidSystemID\"]].drop_duplicates(),\n",
    "        header_sum_by_benefic,\n",
    "        on=\"MedicaidSystemID\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    claims_both = pd.merge(\n",
    "        claims_wheader, detail_sum_by_benefic, on=\"MedicaidSystemID\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    claims_both_final = claims_both.fillna(0)\n",
    "    claims_both_final[\"total_expenditures\"] = (\n",
    "        claims_both_final.HeaderTotalReimbursement\n",
    "        + claims_both_final.DetailReimbursementAmount\n",
    "    )\n",
    "\n",
    "    return claims_both_final\n",
    "\n",
    "\n",
    "def code_topquantile(df: pd.DataFrame, quantiles: dict) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: dataframe\n",
    "        quantiles: dictionary where keys are quantile names; items are values for that quant;\n",
    "        subsetted to those we want to create vars for\n",
    "\n",
    "    Returns:\n",
    "        df: dataframe with indicators added\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for key, item in quantiles.items():\n",
    "        df[\n",
    "            \"is_expend_precall_quantile_\" + re.sub(\"\\\\.\", \"\", str(round(key, 2)))\n",
    "        ] = case_when(df[precall_expend] >= item, True, False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Inputs and Outputs\n",
    "\n",
    "Here we load the inputs to the script, which are largely created in script 060\n",
    "\n",
    "We use the function \"find most recent\" to get the name of the most recent version of the output\n",
    "from the last script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS\n",
    "CLAIMS_IN_WINDOW_FINAL_FILE = INTERMEDIATE_DIR / get_mostrec(\n",
    "    \"Medicaid_analytic_peoplewclaims\", INTERMEDIATE_DIR\n",
    ")\n",
    "\n",
    "### Using output of script 050 so not restricted to first call\n",
    "DECORATED_NTL_OUTPUT_FILE = INTERMEDIATE_DIR / get_mostrec(\n",
    "    \"ntl_withmedicaidIDS\", INTERMEDIATE_DIR\n",
    ")\n",
    "FIRSTCALL_FILE = INTERMEDIATE_DIR / get_mostrec(\"all_analytic\", INTERMEDIATE_DIR)\n",
    "CLAIMS_BEFORECALL_FILE = INTERMEDIATE_DIR / get_mostrec(\n",
    "    \"Medicaid_analytic_precallclaims\", INTERMEDIATE_DIR\n",
    ")\n",
    "STATIC_ATTRIBUTES_FILE = INTERMEDIATE_DIR / get_mostrec(\n",
    "    \"Medicaid_staticattributes\", INTERMEDIATE_DIR\n",
    ")\n",
    "\n",
    "NYU_ED_CODES_FILE = PUBLIC_DATA_DIR / \"nyu_ed.xlsx\"\n",
    "\n",
    "## FLAGS FOR WHETHER TO RUN CERTAIN CODE SECTIONS\n",
    "write_forIDsearch = False\n",
    "\n",
    "\n",
    "## Outputs\n",
    "MISSING_NTL_IDS_FOR_CHRYSANTHI = INTERMEDIATE_DIR / \"ntl_missingidentifiers_forCH.csv\"\n",
    "PTLEVEL_WOUTCOMES_BENEFICONLY = INTERMEDIATE_DIR / \"ptlevel_beneficonly.csv\"\n",
    "PTLEVEL_WOUTCOMES_FORROBUST = INTERMEDIATE_DIR / \"ptlevel_forrobust.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read data and separate into three analytic samples\n",
    "\n",
    "Here, we read the full claims data `Medicaid_analytic_peoplewclaims`, stored as constant `CLAIMS_IN_WINDOW_FINAL_FILE`,  where each person (`MedicaidSystemID`) is repeated across their Medicaid claims\n",
    "\n",
    "NTL-ers fall into three groups:\n",
    "\n",
    "1. People we matched to the beneficiaries file but who have no claims within a 6-month window of their first NTL call\n",
    "2. People we matched to the beneficiaries file and who have 1+ claims within a 6-month window of their first NTL call\n",
    "3. People we did not match to the beneficiaries file (might be true non-beneficiaries or nonmatches due to insufficient/poor identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwilso14/repo/dc/FEMS-911NurseTriageLine-private/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3172: DtypeWarning: Columns (73) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "## first load those with at least one claim within 6 months of call\n",
    "## coding certain cols as objects to prevent conversion to integer when leading\n",
    "## 0's are important\n",
    "claims_inwindow = pd.read_csv(\n",
    "    CLAIMS_IN_WINDOW_FINAL_FILE,\n",
    "    dtype={\"MedicaidSystemID\": \"object\", \"DetailRenderingSpecialtyCode\": \"object\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## then, load full dataset\n",
    "ntl_medicaidstatus_init = pd.read_csv(\n",
    "    DECORATED_NTL_OUTPUT_FILE, dtype={\"MedicaidSystemID\": \"object\"}\n",
    ")\n",
    "## Checking that we have correct # of tx and control\n",
    "assert ntl_medicaidstatus_init.dispo_broad.value_counts()[\"NTL treatment\"] == 3030\n",
    "assert ntl_medicaidstatus_init.dispo_broad.value_counts()[\"NTL control\"] == 3023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5352"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5352"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## finally, load data that restricts ppl to first call (already done\n",
    "## for the those with claims in window in claims_in_window file; not\n",
    "## done for non-matches)\n",
    "firstcall_file = pd.read_csv(FIRSTCALL_FILE, dtype={\"MedicaidSystemID\": \"object\"})\n",
    "\n",
    "## create version of ntl_medicaidstatus restricted to first call\n",
    "## we use num_1 since those are non-repeated across rows\n",
    "## and add new constructed ids\n",
    "ntl_medicaidstatus = pd.merge(\n",
    "    ntl_medicaidstatus_init.loc[\n",
    "        ntl_medicaidstatus_init.num_1.isin(firstcall_file.num_1)\n",
    "    ].copy(),\n",
    "    firstcall_file[[\"num_1\", \"constructed_id_new\"]],\n",
    "    how=\"left\",\n",
    "    on=\"num_1\",\n",
    ")\n",
    "\n",
    "## see that constructed_id_new is not less unique than num_1, so use num_1 for remainder\n",
    "len(ntl_medicaidstatus.num_1.unique())\n",
    "len(ntl_medicaidstatus.constructed_id_new.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Create three analytic datasets: benef with claims in window; benef no claims in window; non-match\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_24hours = claims_inwindow.loc[claims_inwindow.is_within_24_hours == True].copy()\n",
    "claims_6mo = claims_inwindow.loc[\n",
    "    (claims_inwindow.is_within_6_months == True)\n",
    "    | (claims_inwindow.is_within_24_hours == True)\n",
    "].copy()  # includes both 24 hours and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make sure that claims within 6 months encompass claims within 24 hours\n",
    "assert claims_24hours.ClaimTCNText.isin(claims_6mo.ClaimTCNText).all()\n",
    "\n",
    "## clean up status cols\n",
    "## clean up date since we're sorting and restricting to first appearance\n",
    "ntl_medicaidstatus[\"date_call_dateformat\"] = pd.to_datetime(\n",
    "    ntl_medicaidstatus.date, errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coding into 5 mut-ex categories\n",
    "ntl_medicaidstatus[\"claims_status\"] = case_when(\n",
    "    ntl_medicaidstatus.MedicaidSystemID.isin(claims_24hours.MedicaidSystemID),\n",
    "    \"Benefic. with claims in 24-hours window\",\n",
    "    ntl_medicaidstatus.MedicaidSystemID.isin(claims_6mo.MedicaidSystemID),\n",
    "    \"Benefic. with claims not in 24 hours but in 6-months window\",  # 6 months but not 24 hours\n",
    "    (ntl_medicaidstatus.has_medicaid_id == \"Has Medicaid ID\")\n",
    "    & (~ntl_medicaidstatus.MedicaidSystemID.isin(claims_24hours.MedicaidSystemID))\n",
    "    & (~ntl_medicaidstatus.MedicaidSystemID.isin(claims_6mo.MedicaidSystemID)),\n",
    "    \"Benefic. no claims in 6-months window\",\n",
    "    ntl_medicaidstatus.has_medicaid_id == \"Missing Medicaid ID\",\n",
    "    \"Not matched\",\n",
    "    \"Other\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not matched                                                    2285\n",
       "Benefic. with claims in 24-hours window                        2260\n",
       "Benefic. with claims not in 24 hours but in 6-months window     419\n",
       "Benefic. no claims in 6-months window                           388\n",
       "Name: claims_status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## value counts; non-unique since a given beneficiary\n",
    "## can be repeated across calls, so just rough estimate;\n",
    "## uniquify later\n",
    "ntl_medicaidstatus.claims_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_forIDsearch == True:\n",
    "\n",
    "    ## subset to callers not matched to medicaid\n",
    "    ntl_searchIDs = ntl_medicaidstatus.loc[\n",
    "        ntl_medicaidstatus.has_medicaid_id == \"Missing Medicaid ID\",\n",
    "        [\n",
    "            \"num_1\",\n",
    "            \"date\",\n",
    "            \"event_status\",\n",
    "            \"dispo_broad\",\n",
    "            \"all_appearances\",\n",
    "            \"name_giventoMedicaid\",\n",
    "            \"dob_giventoMedicaid\",\n",
    "        ],\n",
    "    ].copy()\n",
    "\n",
    "    ## recode as boolean to help with id status\n",
    "    ntl_searchIDs[\"name_giventoMedicaid\"] = np.where(\n",
    "        ntl_searchIDs.name_giventoMedicaid == 1, True, False\n",
    "    )\n",
    "    ntl_searchIDs[\"dob_giventoMedicaid\"] = np.where(\n",
    "        ntl_searchIDs.dob_giventoMedicaid == 1, True, False\n",
    "    )\n",
    "\n",
    "    ## file to write\n",
    "    ntl_searchIDs_towrite = ntl_searchIDs[\n",
    "        [\"num_1\", \"date\", \"id_status\", \"event_status\", \"dispo_broad\", \"all_appearances\"]\n",
    "    ].drop_duplicates()\n",
    "\n",
    "    ## write\n",
    "    ntl_searchIDs_towrite.to_csv(MISSING_NTL_IDS_FOR_CHRYSANTHI, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create three groups since we'll code their outcomes differently\n",
    "\n",
    "## Group one: matched medicaid beneficiaries with claims in 24 hour or 6 month window\n",
    "## separating to ensure mutually exclusivity with the no claims datasets\n",
    "medicaid_patients_wclaims_24hour = ntl_medicaidstatus.loc[\n",
    "    ntl_medicaidstatus.claims_status.isin([\"Benefic. with claims in 24-hours window\"])\n",
    "].copy()\n",
    "medicaid_patients_firstappear_24hour = (\n",
    "    medicaid_patients_wclaims_24hour.sort_values(by=\"date_call_dateformat\")\n",
    "    .groupby(\"MedicaidSystemID\")\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "medicaid_patients_wclaims_6mo = ntl_medicaidstatus.loc[\n",
    "    ntl_medicaidstatus.claims_status.isin(\n",
    "        [\n",
    "            \"Benefic. with claims in 24-hours window\",\n",
    "            \"Benefic. with claims not in 24 hours but in 6-months window\",\n",
    "        ]\n",
    "    )\n",
    "].copy()\n",
    "medicaid_patients_firstappear_6mo = (\n",
    "    medicaid_patients_wclaims_6mo.sort_values(by=\"date_call_dateformat\")\n",
    "    .groupby(\"MedicaidSystemID\")\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "## Group two: matched medicaid beneficiaries with no claims in 24 hour or 6 month window\n",
    "medicaid_patients_noclaims_24hour = ntl_medicaidstatus.loc[\n",
    "    (\n",
    "        ~ntl_medicaidstatus.MedicaidSystemID.isin(\n",
    "            medicaid_patients_firstappear_24hour.MedicaidSystemID\n",
    "        )\n",
    "    )\n",
    "    & (ntl_medicaidstatus.claims_status != \"Not matched\")\n",
    "].copy()\n",
    "\n",
    "medicaid_patients_noclaims_24ho_firstappear = (\n",
    "    medicaid_patients_noclaims_24hour.sort_values(by=\"date_call_dateformat\")\n",
    "    .groupby(\"MedicaidSystemID\")\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "medicaid_patients_noclaims_6mo = ntl_medicaidstatus.loc[\n",
    "    (\n",
    "        ~ntl_medicaidstatus.MedicaidSystemID.isin(\n",
    "            medicaid_patients_firstappear_6mo.MedicaidSystemID\n",
    "        )\n",
    "    )\n",
    "    & (ntl_medicaidstatus.claims_status != \"Not matched\")\n",
    "].copy()\n",
    "\n",
    "medicaid_patients_noclaims_6mo_firstappear = (\n",
    "    medicaid_patients_noclaims_6mo.sort_values(by=\"date_call_dateformat\")\n",
    "    .groupby(\"MedicaidSystemID\")\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "## Group three: those not matched\n",
    "medicaid_nonmatch = ntl_medicaidstatus.loc[\n",
    "    ntl_medicaidstatus.claims_status == \"Not matched\"\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## then, make sure groups that are mutually exclusive are (not exhaustive)\n",
    "\n",
    "### make sure that no one classified as a non-match to medicaid appears as a beneficiary\n",
    "### with claims\n",
    "overlap_claimnone = set(medicaid_nonmatch.num_1).intersection(\n",
    "    set(medicaid_patients_wclaims_6mo.num_1)\n",
    ")\n",
    "assert len(overlap_claimnone) == 0\n",
    "\n",
    "### make sure that no one classified as having claims within 6 months is also classified\n",
    "### as having no claims in 6 months\n",
    "overlap_claimwindow = set(medicaid_patients_firstappear_6mo.num_1).intersection(\n",
    "    medicaid_patients_noclaims_6mo_firstappear.num_1\n",
    ")\n",
    "assert len(overlap_claimwindow) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create vectors of ids to check so that we can check later they're included\n",
    "bene_24ho_init = ntl_medicaidstatus.MedicaidSystemID[\n",
    "    ntl_medicaidstatus.claims_status == \"Benefic. with claims in 24-hours window\"\n",
    "].to_list()\n",
    "bene_6mo_init = (\n",
    "    bene_24ho_init\n",
    "    + ntl_medicaidstatus.MedicaidSystemID[\n",
    "        ntl_medicaidstatus.claims_status\n",
    "        == \"Benefic. with claims not in 24 hours but in 6-months window\"\n",
    "    ].to_list()\n",
    ")\n",
    "bene_all_init = (\n",
    "    bene_6mo_init\n",
    "    + ntl_medicaidstatus.MedicaidSystemID[\n",
    "        ntl_medicaidstatus.claims_status == \"Benefic. no claims in 6-months window\"\n",
    "    ].to_list()\n",
    ")\n",
    "\n",
    "## deduplicate\n",
    "bene_24ho = list(set(bene_24ho_init))\n",
    "bene_6mo = list(set(bene_6mo_init))\n",
    "bene_all = list(set(bene_all_init))\n",
    "\n",
    "## check to see that all the beneficiaries are in the\n",
    "## set addition of (1) patients w/ some claims and (2) patients w/ no claims\n",
    "missing_noclaims_24ho = set(bene_all).difference(\n",
    "    set(\n",
    "        medicaid_patients_noclaims_24ho_firstappear.MedicaidSystemID.to_list()\n",
    "        + medicaid_patients_firstappear_24hour.MedicaidSystemID.to_list()\n",
    "    )\n",
    ")\n",
    "missing_noclaims_6mo = set(bene_all).difference(\n",
    "    set(\n",
    "        medicaid_patients_noclaims_6mo_firstappear.MedicaidSystemID.to_list()\n",
    "        + medicaid_patients_firstappear_6mo.MedicaidSystemID.to_list()\n",
    "    )\n",
    ")\n",
    "\n",
    "assert len(missing_noclaims_24ho) == 0\n",
    "assert len(missing_noclaims_6mo) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In later analyses, check to make sure there are 3067 unique beneficiaries\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"In later analyses, check to make sure there are \"\n",
    "    + str(len(bene_all))\n",
    "    + \" unique beneficiaries\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Code whether a claim is associated with an ED visit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 First restrict to revenue codes that indicate ED visit; filter out inpatient admit, and merge with respondent ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revenue codes indicating emergency department visit\n",
    "ED_CODES = [f\"045{idx}\" for idx in range(10)]\n",
    "PROF_ED_CODE = [\"0981\"]\n",
    "ED_VISIT_CODES = ED_CODES + PROF_ED_CODE\n",
    "\n",
    "# Procedure codes indicating an ED physician\n",
    "ED_PHYSICIAN_CODES = [\"99281\", \"99282\", \"99283\", \"99284\", \"99285\"]\n",
    "\n",
    "# revenue codes for whether the visit resulted in an inpatient stay\n",
    "ROOM_BOARD_CODES = [f\"0{idx}\" for idx in range(100, 220)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct ed visits in different windows\n",
    "edvisits_24hours = construct_edvisit(claims_24hours)\n",
    "edvisits_6months = construct_edvisit(claims_6mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add beneficiary information on to claims information\n",
    "edvisits_24hours_wntl = mergeclaims_beneficiaries(\n",
    "    edvisits_24hours, medicaid_patients_firstappear_24hour\n",
    ")\n",
    "edvisits_6mo_wntl = mergeclaims_beneficiaries(\n",
    "    edvisits_6months, medicaid_patients_firstappear_6mo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## making sure that more visits are in longer time aggregation\n",
    "assert edvisits_6mo_wntl.shape > edvisits_24hours_wntl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Then, construct a general care, non-ED use measure (diff from pcp)\n",
    "\n",
    "Not preregistered but requested analysis for budget hearings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_types_to_remove = [\n",
    "    \"Transportion (includes Amb)\",\n",
    "    \"Capitation (MC)\",\n",
    "    \"Nursing Fac & Long Term Care\",\n",
    "]\n",
    "\n",
    "### construct ed visits in different windows\n",
    "generalcare_24hours = construct_nonED_care(claims_24hours, claim_types_to_remove)\n",
    "generalcare_6months = construct_nonED_care(claims_6mo, claim_types_to_remove)\n",
    "\n",
    "## merge with beneficiary\n",
    "generalcare_24hours_wntl = mergeclaims_beneficiaries(\n",
    "    generalcare_24hours, medicaid_patients_firstappear_24hour\n",
    ")\n",
    "generalcare_6mo_wntl = mergeclaims_beneficiaries(\n",
    "    generalcare_6months, medicaid_patients_firstappear_6mo\n",
    ")\n",
    "\n",
    "## not using after so maybe delete code once confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Staying at the ED-visit level, code appropriateness of visit using NYU alg \n",
    "\n",
    "Want to code appropriateness at visit level before aggregating visits within a patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Load and merge nyu codes onto primary dx code at visit level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyu_ed = pd.read_excel(NYU_ED_CODES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 754 unique dx codes in callers claims in 24 hours we matched 719 with the NYU classifications\n",
      "Out of 2016 unique dx codes in callers claims in 6 months we matched 1920 with the NYU classifications\n"
     ]
    }
   ],
   "source": [
    "edvisits_24hours_wntl_wicd = merge_dx_classification(\n",
    "    data=edvisits_24hours_wntl, icd_classify_data=nyu_ed, time_horizon=\"24 hours\"\n",
    ")\n",
    "\n",
    "edvisits_6mo_wntl_wicd = merge_dx_classification(\n",
    "    data=edvisits_6mo_wntl, icd_classify_data=nyu_ed, time_horizon=\"6 months\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Staying at the visit level, code categories of ED visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visit-level classifications\n",
    "edvisits_24ho_wcats = classify_visit_approp(data=edvisits_24hours_wntl_wicd)\n",
    "edvisits_6mo_wcats = classify_visit_approp(data=edvisits_6mo_wntl_wicd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Aggregate up from visit level to the patient level and code binary outcomes for all three groups\n",
    "\n",
    "Related to the three groups above, we construct outcome variables as follows:\n",
    "\n",
    "- For people matched and with claims, use observed outcome var\n",
    "- For people matched but with no claims in window, impute to 0 (since we had chance to observe but affirmatively do not observe ED use, PCP use, etc.)\n",
    "- For people not matched, make two decisions:\n",
    "\n",
    "    1. Who do we want to impute outcomes for? (`inclusion_method`): described below\n",
    "    2. What bound do we want to impute?\n",
    "\n",
    "        - Pessimistic bound: if treatment, impute outcome to bad for treatment effect (e.g., ED use = 1); if control, impute outcome to bad for treatment effect (e.g., ED use = 0)\n",
    "        - Optimistic bound: vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Group 1: matched and some claims in window(s)\n",
    "\n",
    "Aggregate from visit level to patient level for patients with 1+ claim in window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sums\n",
    "ptlevel_ed_24ho = (\n",
    "    edvisits_24ho_wcats.groupby(\"MedicaidSystemID\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"is_unnecessary_ED\": \"sum\",\n",
    "            \"is_necessary_ED\": \"sum\",\n",
    "            \"is_unclassified_ED\": \"sum\",\n",
    "            \"is_not_ED\": \"sum\",\n",
    "            \"dispo_broad\": \"first\",\n",
    "            \"event_status\": \"first\",\n",
    "            \"num_1\": \"first\",\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ptlevel_ed_6mo = (\n",
    "    edvisits_6mo_wcats.groupby(\"MedicaidSystemID\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"is_unnecessary_ED\": \"sum\",\n",
    "            \"is_necessary_ED\": \"sum\",\n",
    "            \"is_not_ED\": \"sum\",\n",
    "            \"is_unclassified_ED\": \"sum\",\n",
    "            \"dispo_broad\": \"first\",\n",
    "            \"event_status\": \"first\",\n",
    "            \"num_1\": \"first\",\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "## binary\n",
    "ed_outcome_vars = [\"is_unnecessary_ED\", \"is_necessary_ED\", \"is_unclassified_ED\"]\n",
    "ptlevel_ed_24ho = construct_binary_measures(\n",
    "    data=ptlevel_ed_24ho, outcome_vars=ed_outcome_vars\n",
    ")\n",
    "\n",
    "\n",
    "ptlevel_ed_6mo = construct_binary_measures(\n",
    "    data=ptlevel_ed_6mo, outcome_vars=ed_outcome_vars\n",
    ")\n",
    "\n",
    "ed_outcome_vars_binary = [var + \"_1ormore\" for var in ed_outcome_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Group 2: matched and no claims in window(s)\n",
    "\n",
    "For this group, coding outcomes rather than \"imputing\"/bounding the outcomes, since we affirmatively observed no claims in that window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add in matched beneficiaries with no claims as zero\n",
    "ptlevel_ed_noclaims_24ho = code_noclaims(\n",
    "    df=medicaid_patients_noclaims_24ho_firstappear,\n",
    "    outcome_varnames=ed_outcome_vars_binary,\n",
    ")\n",
    "ptlevel_ed_noclaims_6mo = code_noclaims(\n",
    "    df=medicaid_patients_noclaims_6mo_firstappear,\n",
    "    outcome_varnames=ed_outcome_vars_binary,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Group 3: not matched\n",
    "\n",
    "In function documentation for `impute_nonmatches` we specify three options for inclusion methods for ntl callers not matched to beneficiary file\n",
    "\n",
    "Here, we use the \"conservative\" definition of who we should impute outcomes for (people with neither name nor DOB to give to Medicaid to try to match) and code both optimistic and pessimistic bounds as separate datasets\n",
    "\n",
    "Then, after specifying who we include and setting placeholder values for them, we use the `bound_binary` function to impute optimistic and pessimistic bounds for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, code indicator for whether\n",
    "## it's missing either name and dob\n",
    "## (true)\n",
    "## or false\n",
    "medicaid_nonmatch[\"is_miss_nameordob\"] = np.where(\n",
    "    (~medicaid_nonmatch.has_medicaid_name) | (~medicaid_nonmatch.has_medicaid_dob),\n",
    "    True,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## then, return new cols for those nonmatches included using the\n",
    "## specified inclusion method\n",
    "ptlevel_ed_noclaims_notbene = impute_nonmatch(\n",
    "    medicaid_nonmatch,\n",
    "    inclusion_method=\"analytic_conservative\",\n",
    "    outcome_varnames=ed_outcome_vars_binary,\n",
    ")\n",
    "\n",
    "## then, add optimistic and pessimistic bounds\n",
    "ptlevel_ed_noclaims_notbene_wbounds_init = bound_binary(\n",
    "    ptlevel_ed_noclaims_notbene,\n",
    "    cols_tobound=[\"is_unnecessary_ED_1ormore\", \"is_unclassified_ED_1ormore\"],\n",
    ")  # bound these so that tx = 0\n",
    "\n",
    "ptlevel_ed_noclaims_notbene_wbounds = bound_binary(\n",
    "    ptlevel_ed_noclaims_notbene_wbounds_init,\n",
    "    cols_tobound=[\"is_necessary_ED_1ormore\"],\n",
    "    optimistic_tx=False,\n",
    ")\n",
    "\n",
    "## drop nonbounded version\n",
    "ptlevel_ed_noclaims_notbene_wbounds.drop(columns=ed_outcome_vars_binary, inplace=True)\n",
    "ptlevel_ed_noclaims_notbene_wbounds[\"participant_group\"] = \"Not matched\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Rowbind and summarize \n",
    "\n",
    "How we rowbind the three groups using the following process:\n",
    "\n",
    "- Patients not matched are the only group with pessimistic/optimistic bounds\n",
    "- For the other two groups---benefic w/ claims and those matched but w/ no claims--- we copy the cols and add the suffix optimistic and pessimistic\n",
    "- This creates a wide dataset with both sets of outcomes\n",
    "- We also construct a flag indicating which of the three groups the record belongs to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Create equivalent columns across the three groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, for ones with matched and with some claims, copy over\n",
    "## observed cols as opt and pessmistic\n",
    "ptlevel_ed_24ho_torbind = add_bounds_suffix(\n",
    "    ed_outcome_vars_binary, ptlevel_ed_24ho, participant_group=\"Matched + claims\"\n",
    ")\n",
    "\n",
    "ptlevel_ed_6mo_torbind = add_bounds_suffix(\n",
    "    ed_outcome_vars_binary, ptlevel_ed_6mo, participant_group=\"Matched + claims\"\n",
    ")\n",
    "\n",
    "## then, for ones with matched and no claims, similar copying\n",
    "ptlevel_ed_noclaims_24ho_torbind = add_bounds_suffix(\n",
    "    ed_outcome_vars_binary,\n",
    "    ptlevel_ed_noclaims_24ho,\n",
    "    participant_group=\"Matched no claims\",\n",
    ")\n",
    "\n",
    "ptlevel_ed_noclaims_6mo_torbind = add_bounds_suffix(\n",
    "    ed_outcome_vars_binary,\n",
    "    ptlevel_ed_noclaims_6mo,\n",
    "    participant_group=\"Matched no claims\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Datasets 1: only matched beneficiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset to column cols (just removes some extraneous ones like the 1 or more flags we created during aggregation)\n",
    "cols_touse = set(ptlevel_ed_noclaims_24ho_torbind.columns).intersection(\n",
    "    set(ptlevel_ed_24ho_torbind.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_ed_allbenefic_24ho = pd.concat(\n",
    "    [ptlevel_ed_24ho_torbind[cols_touse], ptlevel_ed_noclaims_24ho_torbind[cols_touse]],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")\n",
    "ptlevel_ed_allbenefic_6mo = pd.concat(\n",
    "    [ptlevel_ed_6mo_torbind[cols_touse], ptlevel_ed_noclaims_6mo_torbind[cols_touse]],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ptlevel_ed_allbenefic_24ho.shape[0] == ptlevel_ed_allbenefic_6mo.shape[0]\n",
    "\n",
    "## make sure there are no beneficiaries missing from aggregation\n",
    "missing_bene_ed = set(bene_all).difference(\n",
    "    ptlevel_ed_allbenefic_6mo.MedicaidSystemID.to_list()\n",
    ")\n",
    "\n",
    "assert len(missing_bene_ed) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "rate within 24 hours when we include all beneficiaries\n",
      "is_unnecessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                       \n",
      "NTL control                            1155    488\n",
      "NTL treatment                          1066    358\n",
      "is_unnecessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                       \n",
      "NTL control                          0.7030 0.2970\n",
      "NTL treatment                        0.7486 0.2514\n",
      "-------------------------------\n",
      "rate within 24 hours when we include all beneficiaries\n",
      "is_necessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                     \n",
      "NTL control                          1317    326\n",
      "NTL treatment                        1203    221\n",
      "is_necessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                     \n",
      "NTL control                        0.8016 0.1984\n",
      "NTL treatment                      0.8448 0.1552\n",
      "-------------------------------\n",
      "rate within 24 hours when we include all beneficiaries\n",
      "is_unclassified_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                        \n",
      "NTL control                             1619     24\n",
      "NTL treatment                           1406     18\n",
      "is_unclassified_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                        \n",
      "NTL control                           0.9854 0.0146\n",
      "NTL treatment                         0.9874 0.0126\n",
      "-------------------------------\n",
      "rate within 6 months when we include all beneficiaries\n",
      "is_unnecessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                       \n",
      "NTL control                             929    714\n",
      "NTL treatment                           808    616\n",
      "is_unnecessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                       \n",
      "NTL control                          0.5654 0.4346\n",
      "NTL treatment                        0.5674 0.4326\n",
      "-------------------------------\n",
      "rate within 6 months when we include all beneficiaries\n",
      "is_necessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                     \n",
      "NTL control                          1089    554\n",
      "NTL treatment                         973    451\n",
      "is_necessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                     \n",
      "NTL control                        0.6628 0.3372\n",
      "NTL treatment                      0.6833 0.3167\n",
      "-------------------------------\n",
      "rate within 6 months when we include all beneficiaries\n",
      "is_unclassified_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                        \n",
      "NTL control                             1593     50\n",
      "NTL treatment                           1376     48\n",
      "is_unclassified_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                        \n",
      "NTL control                           0.9696 0.0304\n",
      "NTL treatment                         0.9663 0.0337\n"
     ]
    }
   ],
   "source": [
    "## print outcomes\n",
    "### note that since optimistic and pessimistic are identical cols\n",
    "### for beneficiaries, doing optimistic for convenience, but this is\n",
    "### observed rather than bounded\n",
    "for var in [x + \"_optimistic\" for x in ed_outcome_vars_binary]:\n",
    "    print(\n",
    "        \"-------------------------------\\nrate within 24 hours when we include all beneficiaries\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_ed_allbenefic_24ho, col=var)\n",
    "\n",
    "for var in [x + \"_optimistic\" for x in ed_outcome_vars_binary]:\n",
    "    print(\n",
    "        \"-------------------------------\\nrate within 6 months when we include all beneficiaries\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_ed_allbenefic_6mo, col=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3 Datasets 2: including non-matches based on inclusion criteria above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "rate within 24 hours when we include beneficiaries + opt bounds on some non-matches\n",
      "is_unnecessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                       \n",
      "NTL control                            1155    870\n",
      "NTL treatment                          1658    358\n",
      "is_unnecessary_ED_1ormore_optimistic  False  True \n",
      "dispo_broad                                       \n",
      "NTL control                          0.5704 0.4296\n",
      "NTL treatment                        0.8224 0.1776\n",
      "-------------------------------\n",
      "rate within 24 hours when we include beneficiaries + pess bounds on some non-matches\n",
      "is_unnecessary_ED_1ormore_pessimistic  False  True \n",
      "dispo_broad                                        \n",
      "NTL control                             1537    488\n",
      "NTL treatment                           1066    950\n",
      "is_unnecessary_ED_1ormore_pessimistic  False  True \n",
      "dispo_broad                                        \n",
      "NTL control                           0.7590 0.2410\n",
      "NTL treatment                         0.5288 0.4712\n"
     ]
    }
   ],
   "source": [
    "ptlevel_ed_all_24ho = pd.concat(\n",
    "    [ptlevel_ed_allbenefic_24ho, ptlevel_ed_noclaims_notbene_wbounds], axis=0, sort=True\n",
    ")\n",
    "\n",
    "ptlevel_ed_all_6mo = pd.concat(\n",
    "    [ptlevel_ed_allbenefic_6mo, ptlevel_ed_noclaims_notbene_wbounds], axis=0, sort=True\n",
    ")\n",
    "\n",
    "for var in [x + \"_optimistic\" for x in [\"is_unnecessary_ED_1ormore\"]]:\n",
    "    print(\n",
    "        \"-------------------------------\\nrate within 24 hours when we include beneficiaries + opt bounds on some non-matches\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_ed_all_24ho, col=var)\n",
    "\n",
    "for var in [x + \"_pessimistic\" for x in [\"is_unnecessary_ED_1ormore\"]]:\n",
    "    print(\n",
    "        \"-------------------------------\\nrate within 24 hours when we include beneficiaries + pess bounds on some non-matches\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_ed_all_24ho, col=var)\n",
    "\n",
    "## remove version of variabl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Rename columns and merge beneficiaries data\n",
    "\n",
    "Merging beneficiaries on `MedicaidSystemID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, list of columns to not add time horizon suffix to\n",
    "cols_toshield = [\"MedicaidSystemID\", \"dispo_broad\", \"event_status\", \"num_1\"]\n",
    "\n",
    "ptlevel_ed_allbenefic_24ho.columns = [\n",
    "    col + \"_24ho\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_ed_allbenefic_24ho.columns\n",
    "]\n",
    "ptlevel_ed_allbenefic_6mo.columns = [\n",
    "    col + \"_6mo\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_ed_allbenefic_6mo.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all beneficiaries + imputed non-matches\n",
    "## (can remove latter group using participant_group column)\n",
    "ptlevel_ed_allbenefic_forfin = pd.merge(\n",
    "    ptlevel_ed_allbenefic_24ho,\n",
    "    ptlevel_ed_allbenefic_6mo.drop(\n",
    "        columns=[\"dispo_broad\", \"event_status\", \"num_1\"], axis=1, inplace=False\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"MedicaidSystemID\",\n",
    "    indicator=\"check_merge\",\n",
    ")\n",
    "\n",
    "assert all(x == \"both\" for x in ptlevel_ed_allbenefic_forfin.check_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Rename columns and merge \"all\" data\n",
    "\n",
    "Since MedicaidSystemID is NA for non-beneficiaries, merge on ntl identifier num_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_ed_all_24ho.columns = [\n",
    "    col + \"_24ho\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_ed_all_24ho.columns\n",
    "]\n",
    "ptlevel_ed_all_6mo.columns = [\n",
    "    col + \"_6mo\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_ed_all_6mo.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_ed_all_forfin = pd.merge(\n",
    "    ptlevel_ed_all_24ho,\n",
    "    ptlevel_ed_all_6mo.drop(\n",
    "        columns=[\"dispo_broad\", \"event_status\", \"MedicaidSystemID\"],\n",
    "        axis=1,\n",
    "        inplace=False,\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"num_1\",\n",
    "    indicator=\"check_merge_all\",\n",
    ")\n",
    "\n",
    "assert all(x == \"both\" for x in ptlevel_ed_all_forfin.check_merge_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Primary care visits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Code whether line item is PCP visit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_codes = [\"004\", \"006\", \"012\", \"013\", \"031\", \"044\"]\n",
    "type_code = [\"X05\"]\n",
    "procedure_codes = [\n",
    "    \"T1015\",\n",
    "    \"99201\",\n",
    "    \"99202\",\n",
    "    \"99203\",\n",
    "    \"99204\",\n",
    "    \"99205\",\n",
    "    \"99211\",\n",
    "    \"99212\",\n",
    "    \"99213\",\n",
    "    \"99214\",\n",
    "    \"99215\",\n",
    "]\n",
    "fqhc_specialty_code = [\"801\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, since vars can sometimes get warped from strings -> int during write/read\n",
    "## make sure we have correct intersections since, with the same of claims data we have\n",
    "## there should be at least one overlapping code\n",
    "assert (\n",
    "    len(\n",
    "        set(specialty_codes).intersection(\n",
    "            claims_24hours.DetailRenderingSpecialtyCode.unique()\n",
    "        )\n",
    "    )\n",
    "    != 0\n",
    ")\n",
    "assert (\n",
    "    len(set(type_code).intersection(claims_24hours.BillingProviderTypeCode.unique()))\n",
    "    != 0\n",
    ")\n",
    "assert (\n",
    "    len(set(procedure_codes).intersection(claims_24hours.ProcedureCode.unique())) != 0\n",
    ")\n",
    "assert (\n",
    "    len(\n",
    "        set(fqhc_specialty_code).intersection(\n",
    "            claims_24hours.DetailRenderingSpecialtyCode.unique()\n",
    "        )\n",
    "    )\n",
    "    != 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_24hours_wPCP = code_PCP_visits(df=claims_24hours)\n",
    "claims_6mo_wPCP = code_PCP_visits(df=claims_6mo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Aggregate PCP visits up to patient level and construct binary measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_PCP_24ho = construct_ptlevel_PCP(df=claims_24hours_wPCP)\n",
    "ptlevel_PCP_6mo = construct_ptlevel_PCP(df=claims_6mo_wPCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge with NTL data\n",
    "ptlevel_PCP_24ho_wNTL = mergeclaims_beneficiaries(\n",
    "    ptlevel_PCP_24ho, medicaid_patients_firstappear_24hour\n",
    ")\n",
    "\n",
    "ptlevel_PCP_6mo_wNTL = mergeclaims_beneficiaries(\n",
    "    ptlevel_PCP_6mo, medicaid_patients_firstappear_6mo\n",
    ")\n",
    "\n",
    "pcp_outcome_vars_binary = [\"is_PCP_oneormore\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Create similar ptlevel data for beneficiaries with no claims and non-beneficiaries\n",
    "\n",
    "Follow same process as for ED visit outcomes:\n",
    "\n",
    "- For beneficiaries with no claims, code them as false\n",
    "- For non-matches we're including, create bounds: (1) optimistic is that treatment group always has PCP visit; control group doesn't; (2) pessimistic vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Beneficiaries with no claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_PCP_noclaims_24ho = code_noclaims(\n",
    "    df=medicaid_patients_noclaims_24ho_firstappear,\n",
    "    outcome_varnames=pcp_outcome_vars_binary,\n",
    ")\n",
    "ptlevel_PCP_noclaims_6mo = code_noclaims(\n",
    "    df=medicaid_patients_noclaims_6mo_firstappear,\n",
    "    outcome_varnames=pcp_outcome_vars_binary,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Nonmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_PCP_noclaims_notbene = impute_nonmatch(\n",
    "    medicaid_nonmatch,\n",
    "    inclusion_method=\"analytic_conservative\",\n",
    "    outcome_varnames=pcp_outcome_vars_binary,\n",
    ")\n",
    "\n",
    "## then, add optimistic and pessimistic bounds\n",
    "ptlevel_PCP_noclaims_notbene_wbounds = bound_binary(\n",
    "    ptlevel_PCP_noclaims_notbene,\n",
    "    cols_tobound=pcp_outcome_vars_binary,\n",
    "    optimistic_tx=True,\n",
    ")  # bound these so that tx = true visit to pcp\n",
    "\n",
    "\n",
    "## drop nonbounded version\n",
    "ptlevel_PCP_noclaims_notbene_wbounds.drop(columns=pcp_outcome_vars_binary, inplace=True)\n",
    "ptlevel_PCP_noclaims_notbene_wbounds[\"participant_group\"] = \"Not matched\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Rowbind and summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Rename cols to bindable with bounding vars df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, for ones with matched and with some claims, copy over\n",
    "## observed cols as opt and pessmistic\n",
    "ptlevel_PCP_24ho_torbind = add_bounds_suffix(\n",
    "    pcp_outcome_vars_binary, ptlevel_PCP_24ho_wNTL, participant_group=\"Matched + claims\"\n",
    ")\n",
    "\n",
    "ptlevel_PCP_6mo_torbind = add_bounds_suffix(\n",
    "    pcp_outcome_vars_binary, ptlevel_PCP_6mo_wNTL, participant_group=\"Matched + claims\"\n",
    ")\n",
    "\n",
    "## then, for ones with matched and no claims, similar copying\n",
    "ptlevel_PCP_noclaims_24ho_torbind = add_bounds_suffix(\n",
    "    pcp_outcome_vars_binary,\n",
    "    ptlevel_PCP_noclaims_24ho,\n",
    "    participant_group=\"Matched no claims\",\n",
    ")\n",
    "\n",
    "ptlevel_PCP_noclaims_6mo_torbind = add_bounds_suffix(\n",
    "    pcp_outcome_vars_binary,\n",
    "    ptlevel_PCP_noclaims_6mo,\n",
    "    participant_group=\"Matched no claims\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Dataset 1: beneficiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_touse_PCP = set(ptlevel_PCP_24ho_torbind.columns).intersection(\n",
    "    ptlevel_PCP_noclaims_24ho_torbind.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_PCP_allbenefic_24ho = pd.concat(\n",
    "    [\n",
    "        ptlevel_PCP_24ho_torbind[cols_touse_PCP],\n",
    "        ptlevel_PCP_noclaims_24ho_torbind[cols_touse_PCP],\n",
    "    ],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")\n",
    "ptlevel_PCP_allbenefic_6mo = pd.concat(\n",
    "    [\n",
    "        ptlevel_PCP_6mo_torbind[cols_touse_PCP],\n",
    "        ptlevel_PCP_noclaims_6mo_torbind[cols_touse_PCP],\n",
    "    ],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make sure they're the same nrows and match length of beneficiaries\n",
    "assert ptlevel_PCP_allbenefic_24ho.shape[0] == ptlevel_PCP_allbenefic_6mo.shape[0]\n",
    "missing_bene_PCP = set(bene_all).difference(\n",
    "    ptlevel_PCP_allbenefic_6mo.MedicaidSystemID.to_list()\n",
    ")\n",
    "assert len(missing_bene_ed) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "rate within 24 hours when we include all beneficiaries\n",
      "is_PCP_oneormore_optimistic  False  True \n",
      "dispo_broad                              \n",
      "NTL control                   1602     41\n",
      "NTL treatment                 1307    117\n",
      "is_PCP_oneormore_optimistic  False  True \n",
      "dispo_broad                              \n",
      "NTL control                 0.9750 0.0250\n",
      "NTL treatment               0.9178 0.0822\n",
      "-------------------------------\n",
      "rate within 6 months when we include all beneficiaries\n",
      "is_PCP_oneormore_optimistic  False  True \n",
      "dispo_broad                              \n",
      "NTL control                    931    712\n",
      "NTL treatment                  815    609\n",
      "is_PCP_oneormore_optimistic  False  True \n",
      "dispo_broad                              \n",
      "NTL control                 0.5666 0.4334\n",
      "NTL treatment               0.5723 0.4277\n"
     ]
    }
   ],
   "source": [
    "## print raw rates; similar as to ED, we use the suffix for rowbinding\n",
    "## convenience but these are observed rather than bounded\n",
    "for var in [x + \"_optimistic\" for x in pcp_outcome_vars_binary]:\n",
    "    print(\n",
    "        \"-------------------------------\\nrate within 24 hours when we include all beneficiaries\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_PCP_allbenefic_24ho, col=var)\n",
    "\n",
    "for var in [x + \"_optimistic\" for x in pcp_outcome_vars_binary]:\n",
    "    print(\n",
    "        \"-------------------------------\\nrate within 6 months when we include all beneficiaries\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_PCP_allbenefic_6mo, col=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Dataset 2: beneficiaries + select non-matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "rate within 24 hours when we include beneficiaries + opt bounds on some non-matches\n",
      "is_PCP_oneormore_optimistic  False  True \n",
      "dispo_broad                              \n",
      "NTL control                   1984     41\n",
      "NTL treatment                 1307    709\n",
      "is_PCP_oneormore_optimistic  False  True \n",
      "dispo_broad                              \n",
      "NTL control                 0.9798 0.0202\n",
      "NTL treatment               0.6483 0.3517\n",
      "-------------------------------\n",
      "rate within 24 hours when we include beneficiaries + pess bounds on some non-matches\n",
      "is_PCP_oneormore_pessimistic  False  True \n",
      "dispo_broad                               \n",
      "NTL control                    1602    423\n",
      "NTL treatment                  1899    117\n",
      "is_PCP_oneormore_pessimistic  False  True \n",
      "dispo_broad                               \n",
      "NTL control                  0.7911 0.2089\n",
      "NTL treatment                0.9420 0.0580\n"
     ]
    }
   ],
   "source": [
    "ptlevel_PCP_all_24ho = pd.concat(\n",
    "    [ptlevel_PCP_allbenefic_24ho, ptlevel_PCP_noclaims_notbene_wbounds],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")\n",
    "\n",
    "ptlevel_PCP_all_6mo = pd.concat(\n",
    "    [ptlevel_PCP_allbenefic_6mo, ptlevel_PCP_noclaims_notbene_wbounds],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")\n",
    "\n",
    "for var in [x + \"_optimistic\" for x in pcp_outcome_vars_binary]:\n",
    "    print(\n",
    "        \"-------------------------------\\nrate within 24 hours when we include beneficiaries + opt bounds on some non-matches\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_PCP_all_24ho, col=var)\n",
    "\n",
    "for var in [x + \"_pessimistic\" for x in pcp_outcome_vars_binary]:\n",
    "    print(\n",
    "        \"-------------------------------\\nrate within 24 hours when we include beneficiaries + pess bounds on some non-matches\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_PCP_all_24ho, col=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Rename columns and merge beneficaries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_PCP_allbenefic_24ho.columns = [\n",
    "    col + \"_24ho\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_PCP_allbenefic_24ho.columns\n",
    "]\n",
    "ptlevel_PCP_allbenefic_6mo.columns = [\n",
    "    col + \"_6mo\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_PCP_allbenefic_6mo.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all beneficiaries + imputed non-matches\n",
    "## (can remove latter group using participant_group column)\n",
    "ptlevel_PCP_allbenefic_forfin = pd.merge(\n",
    "    ptlevel_PCP_allbenefic_24ho,\n",
    "    ptlevel_PCP_allbenefic_6mo.drop(\n",
    "        columns=[\"dispo_broad\", \"event_status\", \"num_1\"], axis=1, inplace=False\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"MedicaidSystemID\",\n",
    "    indicator=\"check_merge\",\n",
    ")\n",
    "\n",
    "assert all(x == \"both\" for x in ptlevel_PCP_allbenefic_forfin.check_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Rename columns and merge with non-beneficiaries\n",
    "\n",
    "Similar to ED, merge using `num_1` rather than `MedicaidSystemID` since latter is NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_PCP_all_24ho.columns = [\n",
    "    col + \"_24ho\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_PCP_all_24ho.columns\n",
    "]\n",
    "ptlevel_PCP_all_6mo.columns = [\n",
    "    col + \"_6mo\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_PCP_all_6mo.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_PCP_all_forfin = pd.merge(\n",
    "    ptlevel_PCP_all_24ho,\n",
    "    ptlevel_PCP_all_6mo.drop(\n",
    "        columns=[\"dispo_broad\", \"event_status\", \"MedicaidSystemID\"],\n",
    "        axis=1,\n",
    "        inplace=False,\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"num_1\",\n",
    "    indicator=\"check_merge_all\",\n",
    ")\n",
    "\n",
    "assert all(x == \"both\" for x in ptlevel_PCP_all_forfin.check_merge_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Expenditures\n",
    "\n",
    "For expenditures, since there are no meaningful values to impute / bound non-beneficiaries with, our sole dataset is comprimised of medicaid beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Aggregate expenditures by beneficiary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_24hours_wexpend = summarize_expenditures(df=claims_24hours)\n",
    "claims_6mo_wexpend = summarize_expenditures(df=claims_6mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge with NTL data\n",
    "ptlevel_expend_24ho_wNTL = mergeclaims_beneficiaries(\n",
    "    claims_24hours_wexpend, medicaid_patients_firstappear_24hour\n",
    ")\n",
    "\n",
    "ptlevel_expend_6mo_wNTL = mergeclaims_beneficiaries(\n",
    "    claims_6mo_wexpend, medicaid_patients_firstappear_6mo\n",
    ")\n",
    "## look at dim\n",
    "if ptlevel_expend_24ho_wNTL.shape[0] != medicaid_patients_firstappear_24hour.shape[0]:\n",
    "    print(\"need to add 0's for people with no expenditures during the aggregation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Add information for beneficiaries with no claims \n",
    "\n",
    "Unlike the binary outcomes, we do NOT construct a dataset with bounds for non-beneficiaries, since there's not a clear way to bound their outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see based on above, that unlike the other outcomes, we lose some patients from\n",
    "## medicaid_patients_first_appear_X because in aggregating expenditures, they have no\n",
    "## rows of expenditures for those claims (could be due to differences between servicedate\n",
    "## and payment date)\n",
    "medicaid_patients_noclaims_24ho_tobind = pd.concat(\n",
    "    [\n",
    "        medicaid_patients_noclaims_24ho_firstappear,\n",
    "        medicaid_patients_firstappear_24hour[\n",
    "            ~medicaid_patients_firstappear_24hour.MedicaidSystemID.isin(\n",
    "                ptlevel_expend_24ho_wNTL.MedicaidSystemID\n",
    "            )\n",
    "        ],\n",
    "    ],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")\n",
    "\n",
    "medicaid_patients_noclaims_6mo_tobind = pd.concat(\n",
    "    [\n",
    "        medicaid_patients_noclaims_6mo_firstappear,\n",
    "        medicaid_patients_firstappear_6mo[\n",
    "            ~medicaid_patients_firstappear_6mo.MedicaidSystemID.isin(\n",
    "                ptlevel_expend_6mo_wNTL.MedicaidSystemID\n",
    "            )\n",
    "        ],\n",
    "    ],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add in matched beneficiaries with no claims as zero\n",
    "expend_outcomes = [\"total_expenditures\"]\n",
    "ptlevel_expend_noclaims_24ho = code_noclaims(\n",
    "    medicaid_patients_noclaims_24ho_tobind, outcome_varnames=expend_outcomes, code_to=0\n",
    ")\n",
    "\n",
    "ptlevel_expend_noclaims_6mo = code_noclaims(\n",
    "    medicaid_patients_noclaims_6mo_tobind, outcome_varnames=expend_outcomes, code_to=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Rowbind and summarize outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_expend_24ho_wNTL[\"participant_group\"] = \"Matched + claims\"\n",
    "ptlevel_expend_6mo_wNTL[\"participant_group\"] = \"Matched + claims\"\n",
    "\n",
    "ptlevel_expend_noclaims_24ho[\"participant_group\"] = \"Matched no claims\"\n",
    "ptlevel_expend_noclaims_6mo[\"participant_group\"] = \"Matched no claims\"\n",
    "\n",
    "\n",
    "cols_touse_expend = set(ptlevel_expend_noclaims_24ho.columns).intersection(\n",
    "    ptlevel_expend_24ho_wNTL.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_expend_allbenefic_24ho = pd.concat(\n",
    "    [\n",
    "        ptlevel_expend_24ho_wNTL[cols_touse_expend],\n",
    "        ptlevel_expend_noclaims_24ho[cols_touse_expend],\n",
    "    ],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")\n",
    "\n",
    "ptlevel_expend_allbenefic_6mo = pd.concat(\n",
    "    [\n",
    "        ptlevel_expend_6mo_wNTL[cols_touse_expend],\n",
    "        ptlevel_expend_noclaims_6mo[cols_touse_expend],\n",
    "    ],\n",
    "    axis=0,\n",
    "    sort=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check size and that no beneficiaries are missing\n",
    "assert ptlevel_expend_allbenefic_24ho.shape[0] == ptlevel_expend_allbenefic_6mo.shape[0]\n",
    "missing_bene_exp = set(bene_all).difference(\n",
    "    ptlevel_expend_allbenefic_6mo.MedicaidSystemID.to_list()\n",
    ")\n",
    "assert len(missing_bene_exp) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "mean within 24 hours when we include all beneficiaries\n",
      "dispo_broad\n",
      "NTL control     1091.4425\n",
      "NTL treatment   1253.0608\n",
      "Name: total_expenditures, dtype: float64\n",
      "-------------------------------\n",
      "mean within 6 months when we include all beneficiaries\n",
      "dispo_broad\n",
      "NTL control     9056.1040\n",
      "NTL treatment   8839.2208\n",
      "Name: total_expenditures, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for var in [\"total_expenditures\"]:\n",
    "    print(\n",
    "        \"-------------------------------\\nmean within 24 hours when we include all beneficiaries\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_expend_allbenefic_24ho, col=var, col_type=\"continuous\")\n",
    "\n",
    "for var in [\"total_expenditures\"]:\n",
    "    print(\n",
    "        \"-------------------------------\\nmean within 6 months when we include all beneficiaries\"\n",
    "    )\n",
    "    summarize_bygroup(df=ptlevel_expend_allbenefic_6mo, col=var, col_type=\"continuous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create indicators for different quantiles of pre-call expenditures\n",
    "\n",
    "As prespecified, later will look at heterogeneous impacts on expenditures among different percentiles of pre-call expenditures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Load data,  aggregate expenditures to the beneficiary level, and left join onto expenditures analytic df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwilso14/repo/dc/FEMS-911NurseTriageLine-private/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3172: DtypeWarning: Columns (73) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "claims_precall = pd.read_csv(\n",
    "    CLAIMS_BEFORECALL_FILE, dtype={\"MedicaidSystemID\": \"object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_expend_precall = summarize_expenditures(df=claims_precall)\n",
    "precall_expend = \"total_expenditures_precall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_expend_precall.rename(\n",
    "    columns={\"total_expenditures\": precall_expend}, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## left join using medicaid system ID onto expenditures dataset\n",
    "## so that we know pre-call expenditures for everyone in that df\n",
    "ptlevel_expend_allbenefic_24ho_wprecall = pd.merge(\n",
    "    ptlevel_expend_allbenefic_24ho,\n",
    "    ptlevel_expend_precall[[\"MedicaidSystemID\", precall_expend]],\n",
    "    on=\"MedicaidSystemID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "## since those missing from pre-call expenditures data had 0 claims in 6 months before call,\n",
    "## fill NA with zero\n",
    "ptlevel_expend_allbenefic_24ho_wprecall[\n",
    "    precall_expend\n",
    "] = ptlevel_expend_allbenefic_24ho_wprecall[precall_expend].fillna(0)\n",
    "\n",
    "## repeat for claims within 6 months\n",
    "ptlevel_expend_allbenefic_6mo_wprecall = pd.merge(\n",
    "    ptlevel_expend_allbenefic_6mo,\n",
    "    ptlevel_expend_precall[[\"MedicaidSystemID\", precall_expend]],\n",
    "    on=\"MedicaidSystemID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "## since those missing from pre-call expenditures data had 0 claims in 6 months before call,\n",
    "## fill NA with zero\n",
    "ptlevel_expend_allbenefic_6mo_wprecall[\n",
    "    precall_expend\n",
    "] = ptlevel_expend_allbenefic_6mo_wprecall[precall_expend].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Code whether people are in the top 10% or top 5% of pre-call expenditures (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantiles of expenditures in 6 months pre-call are:----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 0.0,\n",
       " 0.05: 0.0,\n",
       " 0.1: 0.0,\n",
       " 0.15000000000000002: 0.0,\n",
       " 0.2: 0.0,\n",
       " 0.25: 6.835,\n",
       " 0.30000000000000004: 57.72800000000006,\n",
       " 0.35000000000000003: 141.24199999999993,\n",
       " 0.4: 244.60600000000022,\n",
       " 0.45: 426.335,\n",
       " 0.5: 686.72,\n",
       " 0.55: 1111.1250000000005,\n",
       " 0.6000000000000001: 1744.4500000000007,\n",
       " 0.65: 2586.7059999999997,\n",
       " 0.7000000000000001: 3702.724,\n",
       " 0.75: 5297.91,\n",
       " 0.8: 7753.93,\n",
       " 0.8500000000000001: 12398.957000000002,\n",
       " 0.9: 18346.434000000005,\n",
       " 0.9500000000000001: 39541.05299999991}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## quartiles are the same across df since we just left joined the same\n",
    "## 6 months pre call data to the same beneficiary data\n",
    "quantiles = np.arange(0, 1, 0.05).tolist()\n",
    "quantiles_expend = (\n",
    "    ptlevel_expend_allbenefic_6mo_wprecall[precall_expend].quantile(quantiles).to_dict()\n",
    ")\n",
    "print(\"Quantiles of expenditures in 6 months pre-call are:----------------------------\")\n",
    "quantiles_expend\n",
    "quantiles_expend_touse = {k: v for k, v in quantiles_expend.items() if k >= 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_expend_24ho_windicators = code_topquantile(\n",
    "    ptlevel_expend_allbenefic_24ho_wprecall, quantiles_expend_touse\n",
    ")\n",
    "ptlevel_expend_6mo_windicators = code_topquantile(\n",
    "    ptlevel_expend_allbenefic_6mo_wprecall, quantiles_expend_touse\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Rename columns and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptlevel_expend_24ho_windicators.columns = [\n",
    "    col + \"_24ho\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_expend_24ho_windicators\n",
    "]\n",
    "ptlevel_expend_6mo_windicators.columns = [\n",
    "    col + \"_6mo\" if col not in cols_toshield else col\n",
    "    for col in ptlevel_expend_6mo_windicators\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge\n",
    "ptlevel_expend_allbenefic_forfin = pd.merge(\n",
    "    ptlevel_expend_24ho_windicators,\n",
    "    ptlevel_expend_6mo_windicators.drop(\n",
    "        columns=[\"dispo_broad\", \"event_status\", \"num_1\"], axis=1, inplace=False\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    on=\"MedicaidSystemID\",\n",
    "    indicator=\"check_merge\",\n",
    ")\n",
    "\n",
    "assert all(x == \"both\" for x in ptlevel_expend_allbenefic_forfin.check_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Merge all outcomes into same dataset to write\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Main focus: beneficaries only\n",
    "\n",
    "Merge on `MedicaidSystemID` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>static_status</th>\n",
       "      <th>left_only</th>\n",
       "      <th>both</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_group_6mo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Matched + claims</th>\n",
       "      <td>0</td>\n",
       "      <td>2679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matched no claims</th>\n",
       "      <td>308</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "static_status          left_only  both\n",
       "participant_group_6mo                 \n",
       "Matched + claims               0  2679\n",
       "Matched no claims            308    80"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge ED + PCP\n",
    "ptlevel_benefic_edpcp = pd.merge(\n",
    "    ptlevel_ed_allbenefic_forfin.drop([\"check_merge\"], axis=1, inplace=False),\n",
    "    ptlevel_PCP_allbenefic_forfin.drop(\n",
    "        [\n",
    "            \"dispo_broad\",\n",
    "            \"event_status\",\n",
    "            \"num_1\",\n",
    "            \"participant_group_24ho\",\n",
    "            \"participant_group_6mo\",\n",
    "            \"check_merge\",\n",
    "        ],\n",
    "        axis=1,\n",
    "        inplace=False,\n",
    "    ),\n",
    "    on=\"MedicaidSystemID\",\n",
    "    how=\"left\",\n",
    "    indicator=\"check_merge\",\n",
    ")\n",
    "\n",
    "\n",
    "assert all(x == \"both\" for x in ptlevel_benefic_edpcp.check_merge)\n",
    "\n",
    "## merge with expend\n",
    "ptlevel_benefic_edpcpexp = pd.merge(\n",
    "    ptlevel_benefic_edpcp,\n",
    "    ptlevel_expend_allbenefic_forfin.drop(\n",
    "        [\n",
    "            \"dispo_broad\",\n",
    "            \"event_status\",\n",
    "            \"num_1\",\n",
    "            \"participant_group_24ho\",\n",
    "            \"participant_group_6mo\",\n",
    "        ],\n",
    "        axis=1,\n",
    "        inplace=False,\n",
    "    ),\n",
    "    on=\"MedicaidSystemID\",\n",
    "    how=\"left\",\n",
    "    indicator=\"check_merge_2\",\n",
    ")\n",
    "\n",
    "assert all(x == \"both\" for x in ptlevel_benefic_edpcpexp.check_merge_2)\n",
    "\n",
    "## add static attributes OF Medicaid beneficiaries\n",
    "ptlevel_stat_attributes = pd.read_csv(\n",
    "    STATIC_ATTRIBUTES_FILE, dtype={\"MedicaidSystemID\": \"object\"}\n",
    ")\n",
    "\n",
    "## left join static attributes\n",
    "ptlevel_benefic_wattributes = pd.merge(\n",
    "    ptlevel_benefic_edpcpexp,\n",
    "    ptlevel_stat_attributes,\n",
    "    how=\"left\",\n",
    "    indicator=\"static_status\",\n",
    ")\n",
    "\n",
    "## see that most are probably from having no claims in either 6 months\n",
    "## before (not reflected here) or 6 months after (reflected here) in call,\n",
    "## and with attributes coming from the claims data\n",
    "pd.crosstab(\n",
    "    ptlevel_benefic_wattributes.participant_group_6mo,\n",
    "    ptlevel_benefic_wattributes.static_status,\n",
    ")\n",
    "\n",
    "## get rid of extraneous merge cols\n",
    "cols_mergestatus = [\n",
    "    col\n",
    "    for col in ptlevel_benefic_wattributes.columns\n",
    "    if str(col).startswith(\"check_merge\")\n",
    "]\n",
    "cols_tokeep = [\n",
    "    col for col in ptlevel_benefic_wattributes.columns if col not in cols_mergestatus\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write to csv\n",
    "ptlevel_benefic_wattributes[cols_tokeep].to_csv(\n",
    "    PTLEVEL_WOUTCOMES_BENEFICONLY, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6.2 Beneficiaries + imputed values for non-matches\n",
    "\n",
    "Merge on `num_1` rather than `MedicaidSystemID`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge ED + PCP\n",
    "ptlevel_all_edpcp = pd.merge(\n",
    "    ptlevel_ed_all_forfin.drop([\"check_merge_all\"], axis=1, inplace=False),\n",
    "    ptlevel_PCP_all_forfin.drop(\n",
    "        [\n",
    "            \"dispo_broad\",\n",
    "            \"event_status\",\n",
    "            \"MedicaidSystemID\",\n",
    "            \"participant_group_24ho\",\n",
    "            \"participant_group_6mo\",\n",
    "            \"check_merge_all\",\n",
    "        ],\n",
    "        axis=1,\n",
    "        inplace=False,\n",
    "    ),\n",
    "    on=\"num_1\",\n",
    "    how=\"left\",\n",
    "    indicator=\"check_merge\",\n",
    ")\n",
    "\n",
    "\n",
    "assert all(x == \"both\" for x in ptlevel_all_edpcp.check_merge)\n",
    "\n",
    "## write as is since just used for robustness checks on those\n",
    "cols_tokeep = [col for col in ptlevel_all_edpcp.columns if col not in \"check_merge\"]\n",
    "\n",
    "## write to csv\n",
    "ptlevel_all_edpcp[cols_tokeep].to_csv(PTLEVEL_WOUTCOMES_FORROBUST, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d878f940462274e04f0a102860fc57278db93799cf07bd4571911d28a094aaf2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
